import streamlit as st
import fitz
import csv
import re
import pandas as pd
import io

def extract_pdf_data_from_bytes(pdf_bytes, filename):
    """
    Extracts specific data from the left-hand form of each page in the PDF (from bytes).
    """
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    all_data = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        midpoint = page.rect.width / 2
        words = page.get_text("words")

        # Group words on the left side
        left_words = [w for w in words if w[2] < midpoint]

        # 1. Extract 'è£½ç•ª' (Seiban)
        seiban = ""
        for w in left_words:
            if 40 < w[1] < 80:
                if "(" in w[4] or re.match(r'^\d+', w[4]):
                    seiban = w[4]
                    break

        # 2. Extract item rows (å“å, ä»•æ§˜, æ•°é‡)
        rows_data = {}
        for w in left_words:
            x0, y0, x1, y1, text = w[0], w[1], w[2], w[3], w[4]
            if 190 < y0 < 460:
                line_y = round(y0)
                if line_y not in rows_data:
                    rows_data[line_y] = []
                rows_data[line_y].append(w)

        for line_y in sorted(rows_data.keys()):
            line_words = sorted(rows_data[line_y], key=lambda w: w[0])
            himmey = ""
            shiyou = ""
            suuryou = ""
            
            for w in line_words:
                x0, text = w[0], w[4]
                if x0 < 150: # å“å area
                    himmey += text + " "
                elif 200 < x0 < 320: # ä»•æ§˜ area
                    shiyou += text
                elif 350 < x0 < 410: # æ•°é‡ area
                    suuryou = text

            himmey = himmey.strip()
            shiyou_match = re.search(r'^\d+', shiyou)
            shiyou_clean = shiyou_match.group(0) if shiyou_match else ""

            if himmey or shiyou_clean or suuryou:
                if himmey == "å“å" or shiyou == "ä»•æ§˜" or suuryou == "æ•°é‡":
                    continue
                if himmey:
                    all_data.append({
                        "ãƒ•ã‚¡ã‚¤ãƒ«å": filename,
                        "è£½ç•ª": seiban,
                        "å“å": himmey,
                        "ä»•æ§˜": shiyou_clean,
                        "æ•°é‡": suuryou
                    })

    doc.close()
    return all_data

# Streamlit UI
st.set_page_config(page_title="ç¾å“ç¥¨ PDF to CSV Converter", layout="wide")

st.title("ðŸ“„ ç¾å“ç¥¨ PDF to CSV Converter")
st.write("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€å·¦å´ã®ç¾å“ç¥¨ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™ã€‚")

uploaded_files = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("å¤‰æ›é–‹å§‹"):
        all_extracted_data = []
        
        with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...'):
            for uploaded_file in uploaded_files:
                file_bytes = uploaded_file.read()
                data = extract_pdf_data_from_bytes(file_bytes, uploaded_file.name)
                all_extracted_data.extend(data)

        if all_extracted_data:
            st.success(f"{len(uploaded_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(all_extracted_data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
            
            df = pd.DataFrame(all_extracted_data)
            st.dataframe(df, use_container_width=True)

            # CSV Download
            csv_buffer = io.StringIO()
            csv_writer = csv.writer(csv_buffer)
            for row in all_extracted_data:
                csv_writer.writerow([row["è£½ç•ª"], row["å“å"], row["ä»•æ§˜"], row["æ•°é‡"]])
            
            st.download_button(
                label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_buffer.getvalue(),
                file_name="extracted_data.csv",
                mime="text/csv",
            )
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.info("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
